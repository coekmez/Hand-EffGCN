config: '2001'
dataset: hand-lrtraining
dataset_args:
  hand:
    eval_batch_size: 4
    inputs: JVB
    ntu120_path: null
    ntu60_path: ./data
    num_frame: 500
    root_folder: ./numpy_save
    train_batch_size: 4
    transform: true
debug: false
delay_hours: 0
evaluate: false
extract: true
generate_data: false
gpus:
- 0
iterations: 1
lr_scheduler: cosine
model_args:
  act_type: swish
  att_type: stja
  bias: true
  block_args:
  - - 48
    - 1
    - 0.5
  - - 24
    - 1
    - 0.5
  - - 64
    - 2
    - 1
  - - 128
    - 2
    - 1
  drop_prob: 0.25
  edge: true
  expand_ratio: 2
  fusion_stage: 2
  kernel_size:
  - 5
  - 2
  layer_type: Sep
  reduct_ratio: 4
  scale_args:
  - 1.2
  - 1.35
  stem_channel: 64
model_type: EfficientGCN-B0
no_progress_bar: false
optimizer: SGD
optimizer_args:
  Adam:
    betas:
    - 0.9
    - 0.99
    lr: 0.1
    weight_decay: 0.0001
  SGD:
    lr: 0.1
    momentum: 0.9
    nesterov: true
    weight_decay: 0.0001
pretrained_path: ./pretrained_models
resume: false
scheduler_args:
  cosine:
    max_epoch: 70
    warm_up: 10
  step:
    max_epoch: 70
    step_lr:
    - 20
    - 50
    warm_up: 10
seed: 1
visualization_class: 0
visualization_frames: []
visualization_sample: 0
visualize: true
work_dir: ./workdir
